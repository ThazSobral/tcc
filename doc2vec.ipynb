{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "doc2vec.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uH5KS9qwfLCV",
        "JdsRi9KDfoU9",
        "NA1rUfbNnWdU",
        "ZxE7kqpPacay",
        "Qw24m1f-cqlu"
      ],
      "authorship_tag": "ABX9TyPeJFwtIIqL/p9HHApNWg46"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGvVeGgVOwNN"
      },
      "source": [
        "# Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veldBNVVPct9"
      },
      "source": [
        "''' dataframe '''\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "''' utils '''\n",
        "import re\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "import statsmodels.api as sm\n",
        "\n",
        "''' doc2vec '''\n",
        "from gensim.models import doc2vec\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "''' classificação '''\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "''' avaliação '''\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "'''plotagem'''\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHjKx3AiR8El"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLYX_2uzO4c3"
      },
      "source": [
        "# Funções"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAJrc4DjQmdh"
      },
      "source": [
        "## Dados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fmFjKG1SXEe"
      },
      "source": [
        "def read_dataset(path):\n",
        "  return pd.read_csv(path, header=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B8_MmpBQpfI"
      },
      "source": [
        "def build_train_test_data(dataset):\n",
        "\n",
        "  test_size = .3\n",
        "\n",
        "  X = dataset[['id_', 'tweet']]\n",
        "  y = dataset[['flood']]\n",
        "\n",
        "  x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=0)\n",
        "\n",
        "  return x_train, x_test, y_train, y_test, X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjGrBkGXPfW1"
      },
      "source": [
        "def add_column(df, array, column_name):\n",
        "  df[column_name] = array\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR1GbHbm-2BO"
      },
      "source": [
        "def show_values(df, label):\n",
        "  target_count = df[label].value_counts()\n",
        "  print('Class 0:', target_count[0])\n",
        "  print('Class 1:', target_count[1])\n",
        "  print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')\n",
        "\n",
        "  target_count.plot(kind='bar', title='Count (target)',color = ['#1F77B4', '#FF7F0E'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_bTab3kFQVb"
      },
      "source": [
        "def balance_binary_values(df, label_binary, type):\n",
        "  count_class_0, count_class_1 = df[label_binary].value_counts()\n",
        "  \n",
        "  df_class_0 = df[df[label_binary] == 0]\n",
        "  df_class_1 = df[df[label_binary] == 1]\n",
        "\n",
        "  if (type == 'under'):\n",
        "    df_class_0_under = df_class_0.sample(count_class_1)\n",
        "    df = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
        "  elif (type == 'over'):\n",
        "\n",
        "    df_class_0 = df_class_0[:int(len(df_class_0)/2)]\n",
        "\n",
        "    df_class_1_over = df_class_1.sample(int(len(df_class_0)), replace=True)\n",
        "    df = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
        "  else:\n",
        "    print('fail operation')\n",
        "\n",
        "  print(f'Random {type}-sampling:')\n",
        "  print(df[label_binary].value_counts())\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M0tamiYPG4w"
      },
      "source": [
        "## Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "240dSub6Pddf"
      },
      "source": [
        "def tagged_tweets_and_create_documents(corpus):\n",
        "  documents = [TaggedDocument(clear_data(corpus.loc[i].tweet), [i]) for i in corpus.id_]\n",
        "\n",
        "  return documents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4tTT9LrdKVK"
      },
      "source": [
        "def clear_data(text, nums=True):\n",
        "\n",
        "  remove_ellipsis_re = re.compile(r'[^\\.]\\.{2,3}')\n",
        "  punct_re = re.compile(r\"[\\\"'\\[\\],'#.:;()&!@\\u2026]\")\n",
        "  number_re = re.compile(r'\\d+')\n",
        "  mentions_re = re.compile(r'\\B@')\n",
        "  links_re = re.compile(r'(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})')\n",
        "\n",
        "  text = text.lower()\n",
        "\n",
        "  text = text.replace(\"'\",'')\n",
        "\n",
        "  text = re.sub(links_re, '', text)\n",
        "  text = re.sub(mentions_re, '', text)\n",
        "  text = re.sub(remove_ellipsis_re, '', text)\n",
        "  text = re.sub(punct_re, '', text)\n",
        "\n",
        "  if nums:\n",
        "    text = re.sub(number_re, '', text)\n",
        "\n",
        "  return text.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xt3slxsQ0ZL"
      },
      "source": [
        "def create_d2v(documents, type):\n",
        "  ''' definir a quantidade de núcleos do processador para paralelizar o processamento '''\n",
        "  cores = multiprocessing.cpu_count()\n",
        "  # cores = -1\n",
        "  #20\n",
        "  vecs = 28\n",
        "  #10\n",
        "  window = 8\n",
        "  #2\n",
        "  min_count = 2\n",
        "  #0.1\n",
        "  alpha = 0.1\n",
        "  #5\n",
        "  negative = 5\n",
        "  #1e-1\n",
        "  sample = 1e-1\n",
        "\n",
        "  if type == 'dm':\n",
        "    ''' criar modelo dm '''\n",
        "    model = Doc2Vec(vector_size=vecs, window=window, min_count=min_count, workers=cores, dm=1, dm_concat=1, alpha=alpha, sample=sample, negative=negative)\n",
        "    # model = Doc2Vec(vector_size=vecs, window=window, min_count=min_count, workers=cores, dm=1, dm_concat=1)\n",
        "\n",
        "  elif type == 'dbow':\n",
        "    ''' criar modelo dbow '''\n",
        "    model = Doc2Vec(vector_size=vecs, window=window, min_count=min_count, workers=cores, dm=0, alpha=alpha, sample=sample, negative=negative)\n",
        "    # model = Doc2Vec(vector_size=vecs, window=window, min_count=min_count, workers=cores, dm=0)\n",
        "\n",
        "  else: \n",
        "    print('Invalid type!')\n",
        "\n",
        "  model.build_vocab(documents)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DccCCycAfxM9"
      },
      "source": [
        "def save_model(model, fname):\n",
        "  model.save(fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP2mxF9JQ-Mp"
      },
      "source": [
        "import random\n",
        "\n",
        "def train_d2v(model, documents):\n",
        "  epochs = 20\n",
        "\n",
        "  for epoch in range(0, epochs):\n",
        "    print(f'--treinamento na {epoch+1}ª época--')\n",
        "    random.shuffle(documents)\n",
        "    model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hFRyQ3p6RvH"
      },
      "source": [
        "# def get_vector_d2v(model, data):\n",
        "def get_vector_d2v(model_dm, model_dbow, data):\n",
        "\n",
        "  return ( [list(model_dm.docvecs[id]) + list(model_dbow.docvecs[id]) for id in range(0, len(data))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSfEU4ZXPO9u"
      },
      "source": [
        "## Classificação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9RSffgK_Ag3"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maRq2tscPd_X"
      },
      "source": [
        "def create_model_logistic_regression(x, y):\n",
        "  C = 3\n",
        "  penalty = 'l2'\n",
        "  tol = 0.0001\n",
        "  n_jobs = -1\n",
        "\n",
        "  model_log = LogisticRegression(C=C, penalty=penalty, tol=tol, n_jobs=n_jobs)\n",
        "  model_log.fit(x, y)\n",
        "\n",
        "  return model_log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmchvkZCDNk_"
      },
      "source": [
        "## Avaliação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKve9IRkDRCD"
      },
      "source": [
        "def predict_tweet(model_dm, model_dbow, model_classifier, text):\n",
        "  vec_dm = model_dm.infer_vector(doc_words=text.split(), alpha=0.025, steps=20)\n",
        "  vec_dbow = model_dbow.infer_vector(doc_words=text.split(), alpha=0.025, steps=20)\n",
        "\n",
        "  vec = vec_dm + vec_dbow\n",
        "  vec = sm.add_constant(vec)\n",
        "\n",
        "  if (model_classifier.predict(vec.reshape(1, -1)) == 1):\n",
        "    return 1\n",
        "  else: return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y04QlbNlb6g"
      },
      "source": [
        "def avaliation_classification(model_dm, model_dbow, model_classifier, text, label):\n",
        "  vec_dm = model_dm.infer_vector(doc_words=text.split(), alpha=0.025, steps=20)\n",
        "  vec_dbow = model_dbow.infer_vector(doc_words=text.split(), alpha=0.025, steps=20)\n",
        "\n",
        "  vec = vec_dm + vec_dbow\n",
        "  vec = sm.add_constant(vec)\n",
        "  \n",
        "  if (model_classifier.predict(vec.reshape(1, -1)) == label):\n",
        "    return 'right'\n",
        "  else: return 'wrong'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHJqNK4vPwDC"
      },
      "source": [
        "def classifier_test(model, data, label):\n",
        "  predictions = model.predict(data)\n",
        "  print('Testing predicted classes: {}'.format(np.unique(predictions)))\n",
        "  print('Testing accuracy: {}'.format(accuracy_score(label, predictions)))\n",
        "  print('Testing F1 score: {}'.format(f1_score(label, predictions, average='weighted')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkhyBJO-RgEB"
      },
      "source": [
        "def confusion_matrix_test(model, data, label):\n",
        "  predictions = model.predict(data)\n",
        "\n",
        "  cm = confusion_matrix(label, predictions)\n",
        "  print('Confusion matrix:\\n', cm)\n",
        "\n",
        "  labels = ['Class 0', 'Class 1']\n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
        "  fig.colorbar(cax)\n",
        "  ax.set_xticklabels([''] + labels)\n",
        "  ax.set_yticklabels([''] + labels)\n",
        "  plt.xlabel('Predicted')\n",
        "  plt.ylabel('Expected')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAcHkIMaTOoG"
      },
      "source": [
        "def classification_report_test(model, data, label):\n",
        "  predictions = model.predict(data)\n",
        "\n",
        "  print(classification_report(label, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Krsw2E1xO9R-"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KupfXVXLSpx7"
      },
      "source": [
        "df = read_dataset('/content/drive/My Drive/TCC_Thalles Sobral/2-dados/germany/use-data/adjusted.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiXEtqxlZO8v"
      },
      "source": [
        "df = df.drop(columns='hashtag')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh8bgOXY8JHz"
      },
      "source": [
        "TESTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3Hbc23wCElm"
      },
      "source": [
        "df_d2v = df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YweQZ5MO-5hG"
      },
      "source": [
        "df_d2v['flood'] = df_d2v['relevance'].replace([1, 2], [0, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xidp9djG_Cfz"
      },
      "source": [
        "# df_d2v = balance_binary_values(df_d2v, 'flood', 'under')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu82Fid0HNCQ"
      },
      "source": [
        "# show_values(df_d2v, 'flood')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSs7S0Sy_nye"
      },
      "source": [
        "len(df_d2v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s38EG0tQ8MLS"
      },
      "source": [
        "FIM TESTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmwhuUydRf8R"
      },
      "source": [
        "# x_train, x_test, y_train, y_test, all_data =  build_train_test_data(df)\n",
        "x_train, x_test, y_train, y_test, all_data =  build_train_test_data(df_d2v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR9JWbaoPMGp"
      },
      "source": [
        "## Doc2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0luswGuJSEtu"
      },
      "source": [
        "documents = tagged_tweets_and_create_documents(all_data)\n",
        "# documents = tagged_tweets_and_create_documents(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzGVejc-Pell"
      },
      "source": [
        "%time model_d2v_dm = create_d2v(documents, 'dm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFk--xuyqjIn"
      },
      "source": [
        "# %time model_d2v_dm = train_d2v(model_d2v_dm, train_documents, epochs) # conforme o trabalho original foi selecionado 24 épocas]\n",
        "%time model_d2v_dm = train_d2v(model_d2v_dm, documents) # conforme o trabalho original foi selecionado 24 épocas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhxlYJoxhpxh"
      },
      "source": [
        "%time model_d2v_dbow = create_d2v(documents, 'dbow')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBTnyDVDhqSf"
      },
      "source": [
        "# %time model_d2v_dbow = train_d2v(model_d2v_dbow, train_documents, epochs) # conforme o trabalho original foi selecionado 24 épocas\n",
        "%time model_d2v_dbow = train_d2v(model_d2v_dbow, documents) # conforme o trabalho original foi selecionado 24 épocas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7VprO1e59qq"
      },
      "source": [
        "%time all_regressors = get_vector_d2v(model_d2v_dm, model_d2v_dbow, all_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcowsMRF76id"
      },
      "source": [
        "# %time df = add_column(df, all_regressors, 'd2v')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohILtaeyPTej"
      },
      "source": [
        "## Classificação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLoV_HA7D5-b"
      },
      "source": [
        "df = read_dataset('/content/drive/My Drive/TCC_Thalles Sobral/2-dados/germany/use-data/adjusted.csv')\n",
        "df = df.drop(columns='hashtag')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytRb59Pj-SQp"
      },
      "source": [
        "df['flood'] = df['relevance'].replace([1, 2], [0, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxJcm7TkQqYU"
      },
      "source": [
        "show_values(df, 'flood') # tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7eSG10DQqYV"
      },
      "source": [
        "df = balance_binary_values(df, 'flood', 'under') # tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19_2QS6BQqYV"
      },
      "source": [
        "show_values(df, 'flood') # tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf0OdDwgIZRj"
      },
      "source": [
        "# df_d2v = df_d2v.sample(frac=1, axis=0).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzk5USa2QqYV"
      },
      "source": [
        "# x_train, x_test, y_train, y_test, all_data =  build_train_test_data(df_d2v) # tmp\n",
        "x_train, x_test, y_train, y_test, all_data =  build_train_test_data(df) # tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkhjQhTy5ZDc"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCsB9ALDaflJ"
      },
      "source": [
        "%time train_regressors = get_vector_d2v(model_d2v_dm, model_d2v_dbow, x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9maSotW-DPm"
      },
      "source": [
        "# %time model_log = create_model_logistic_regression(all_regressors[:len(y_train)], np.array(y_train))\n",
        "%time model_log = create_model_logistic_regression(train_regressors, y_train.values.ravel())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93ra4-ZaBDOE"
      },
      "source": [
        "# Avaliação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH5KS9qwfLCV"
      },
      "source": [
        "## predict classes - accuracy - F1 score (train datas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObVZRQqb_Ut_"
      },
      "source": [
        "%time train_regressors = get_vector_d2v(model_d2v_dm, model_d2v_dbow, x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r931xzvjKGm"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoHemBR6E-yM"
      },
      "source": [
        "%time classifier_test(model_log, train_regressors, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdsRi9KDfoU9"
      },
      "source": [
        "## predict classes - accuracy - F1 score (test datas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRSx5CHLC7-X"
      },
      "source": [
        "%time test_regressors = get_vector_d2v(model_d2v_dm, model_d2v_dbow, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E3EculSjTyU"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwsg5ke2BXtX"
      },
      "source": [
        "%time classifier_test(model_log, test_regressors, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0qKCocpf0G0"
      },
      "source": [
        "## Predict tweet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldj1pDQDjWv7"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUkrFDY1FkqI"
      },
      "source": [
        "# %time predict_tweet(model_d2v_dm, model_log, df.loc[1].tweet)\n",
        "# %time predict_tweet(model_d2v_dm, model_d2v_dbow, model_log, df.iloc[1].tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA1rUfbNnWdU"
      },
      "source": [
        "## Predict tweet (with answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nznoqo1MnosJ"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqKRqATInaKE"
      },
      "source": [
        "# avaliation_classification(model_d2v, model_log, df.loc[1].tweet, df.loc[1].flood)\n",
        "# avaliation_classification(model_d2v_dm, model_d2v_dbow, model_log, df.iloc[1].tweet, df.iloc[1].flood)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxE7kqpPacay"
      },
      "source": [
        "## Prediction application to the set and classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACGNVeAybTqj"
      },
      "source": [
        "# df_test = df['tweet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U52cwcqtbhds"
      },
      "source": [
        "Logistic Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYGKBKPpawdX"
      },
      "source": [
        "# df_test.apply( lambda x: predict_tweet(model_d2v_dm, model_d2v_dbow, model_log, x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw24m1f-cqlu"
      },
      "source": [
        "## Prediction application to the set and classification (with answer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiyJxYMedDEP"
      },
      "source": [
        "Logistic Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aYtxrRddDEP"
      },
      "source": [
        "# [print(avaliation_classification(model_d2v_dm, model_d2v_dbow, model_log, df.iloc[id].tweet, df.iloc[id].flood)) for id in range(0, len(df))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhMwkAeIlRXz"
      },
      "source": [
        "Salvando resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTFLX3NI1OSA"
      },
      "source": [
        "# df.to_csv('tweets-with-d2v.csv')\n",
        "# !cp tweets-with-d2v.csv \"drive/My Drive/TCC_Thalles Sobral/2-dados/germany/use-data\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMhf_yID6vAn"
      },
      "source": [
        "## Curva ROC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DbNJvJzu-t9"
      },
      "source": [
        "Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vUQ4Zt6uXp_"
      },
      "source": [
        "''' All data'''\n",
        "# labels = df[['flood']].values\n",
        "# %time regressors = get_vector_d2v(model_d2v_dm, model_d2v_dbow, all_data)\n",
        "''' Test data'''\n",
        "labels = y_test\n",
        "%time regressors = get_vector_d2v(model_d2v_dm, model_d2v_dbow, x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8WJ08G-vA52"
      },
      "source": [
        "Plor curve ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu0KvDwrWW0z"
      },
      "source": [
        "\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "''' generate a no skill prediction (majority class) '''\n",
        "\n",
        "ns_probs = [0 for _ in range(len(labels))]\n",
        "\n",
        "''' predict probabilities '''\n",
        "lr_probs = model_log.predict_proba(regressors)\n",
        "# lr_probs = model_log.predict(regressors)\n",
        "\n",
        "''' keep probabilities for the positive outcome only '''\n",
        "lr_probs = lr_probs[:,1]\n",
        "# lr_probs = lr_probs\n",
        "\n",
        "''' calculate scores '''\n",
        "ns_auc = roc_auc_score(labels, ns_probs)\n",
        "lr_auc = roc_auc_score(labels, lr_probs)\n",
        "\n",
        "''' summarize scores '''\n",
        "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
        "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
        "\n",
        "''' calculate roc curves '''\n",
        "ns_fpr, ns_tpr, _ = roc_curve(labels, ns_probs)\n",
        "lr_fpr, lr_tpr, _ = roc_curve(labels, lr_probs)\n",
        "\n",
        "''' plot the roc curve for the model '''\n",
        "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
        "plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
        "\n",
        "''' axis labels '''\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "\n",
        "''' show the legend '''\n",
        "plt.legend()\n",
        "\n",
        "''' show the plot '''\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcuDAxskMdwt"
      },
      "source": [
        "lr_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUAtmezDIlaC"
      },
      "source": [
        "labels.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw_aSlbsftiq"
      },
      "source": [
        "## Confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqGeeqY0jUmU"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZPaLU7fN9x5"
      },
      "source": [
        "%time confusion_matrix_test(model_log, regressors, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHLWkgaw_6A_"
      },
      "source": [
        "## Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QUft22DgIGx"
      },
      "source": [
        "y_pred = model_log.predict(regressors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCqsMi3T_83O"
      },
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdcp4l5mzQoQ"
      },
      "source": [
        "## Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDzz-yawzV4z"
      },
      "source": [
        "%time classification_report_test(model_log, regressors, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcQs6kumFSgC"
      },
      "source": [
        "## dados gerados para um dataset novo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTrMVoxHF-8Y"
      },
      "source": [
        "df = read_dataset('/content/drive/My Drive/TCC_Thalles Sobral/2-dados/germany/use-data/adjusted.csv')\n",
        "df = df.drop(columns='hashtag')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xOokLxaFR0q"
      },
      "source": [
        "# avaliations = []\n",
        "# %time [(avaliations.append(predict_tweet(model_d2v_dm, model_d2v_dbow, model_log, df.iloc[id].tweet))) for id in range(0, len(df))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aOzcn-F-QoD"
      },
      "source": [
        "# avaliations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuriiTkFFfhM"
      },
      "source": [
        "# %time df = add_column(df, avaliations, 'd2v_avaliation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH435Px_J56S"
      },
      "source": [
        "# df.query('d2v_avaliation == 1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCWWEk3EnuGS"
      },
      "source": [
        "# len(df.query('relevance == 2'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_Q3GO6WY2AH"
      },
      "source": [
        "# len(df.query('relevance == 2 and d2v_avaliation == 1'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7EnFXTWzDQa"
      },
      "source": [
        "fazer grafico de dispersão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aTZxiYpcsp7"
      },
      "source": [
        "## Salvando os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dftA9aejQoV8"
      },
      "source": [
        "# df.to_csv('tweets-with-d2v.csv')\n",
        "# !cp tweets-with-d2v.csv \"drive/My Drive/TCC_Thalles Sobral/2-dados/germany/use-data/tweets-with-d2v.csv\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}