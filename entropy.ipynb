{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "entropy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPyUksKyP4Zc1XGkpn5tHRY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSHeS_xX39BC"
      },
      "source": [
        "## Ajuste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8x_00uy4Mlp"
      },
      "source": [
        "Montagem do drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0bO1_zj5BTZ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohoobecC4Zua"
      },
      "source": [
        "## Bibliotecas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3-LaDOL4cz1"
      },
      "source": [
        "Importação de bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11lrFWGC5Kdd"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSPTG0uW4n7R"
      },
      "source": [
        "## Pré-processamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv-A-Ipm5r0p"
      },
      "source": [
        "Filtro por palavras-chave"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_zlIfsq9dqF"
      },
      "source": [
        "# definir as palavras em inglês\n",
        "key_words_english = ['flood']\n",
        "\n",
        "# definir as palavras em alemão\n",
        "key_words_german = ['hochwasser',\n",
        "                    'flut',\n",
        "                    'überschwemmung']\n",
        "\n",
        "# definir as palavras adicionais em alemão\n",
        "key_addiotional_words_german = ['deich',\n",
        "                                'sandsack']\n",
        "\n",
        "# combinar palavras-chave\n",
        "key_words = key_words_english + key_words_german + key_addiotional_words_german"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_ghU06M9ky4"
      },
      "source": [
        "def select_tweets_with_key_words (df):\n",
        "  return df[df.tweet.str.contains('|'.join(key_words), na=False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1XjJej-4tW-"
      },
      "source": [
        "## Aplicação da técnica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSVyrtdm576I"
      },
      "source": [
        "Calcular frequência absoluta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N2f0Tvl9qm-"
      },
      "source": [
        "def calcule_absolute_frequency (tweets):\n",
        "  '''\n",
        "  define um dicionário para registrar as frequências absolutas\n",
        "  onde criamos um dicionário global do dataframe e registramos\n",
        "  a frequência das palavras-chave \n",
        "  '''\n",
        "  absolute_frequency = {}\n",
        "  \n",
        "  for word in key_words:\n",
        "    sum_word = 0\n",
        "    for tweet in tweets:\n",
        "      if (tweet.count(word) > 0): \n",
        "        sum_word += 1\n",
        "    absolute_frequency[word] = sum_word\n",
        "  \n",
        "  return absolute_frequency"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pgb7fPY5-kQ"
      },
      "source": [
        "Calcular frequência relativa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9AEoG6w9tMW"
      },
      "source": [
        "def calcule_relative_frequency (tweet, word, absolute_frequency):\n",
        "  '''\n",
        "  a frequência relativa é a quantidade de aparições de palavras-chave dividio\n",
        "  pela frequência absoluta dessa palavra-chave\n",
        "  '''\n",
        "  return tweet.count(word)/absolute_frequency"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KYAXNqJ6RSy"
      },
      "source": [
        "Calcular entropia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y8EHqsQ9wQb"
      },
      "source": [
        "import math\n",
        "\n",
        "def calcule_tweets_entropy (df):\n",
        "  # definimos um dicionári para a entropia dos tweets\n",
        "  entropies = {}\n",
        "  # realizamos a construção do dicionário de frequência absoluta das palavras chave no tweet\n",
        "  absolute_frequency = calcule_absolute_frequency(df.tweet)\n",
        "  \n",
        "  index = df.index\n",
        "\n",
        "  for id in index:\n",
        "    frequences_array = []\n",
        "    for word in key_words:\n",
        "      if (df.loc[id].tweet.count(word) > 0):\n",
        "        relative_frequency = calcule_relative_frequency(df.loc[id].tweet, word, absolute_frequency[word])\n",
        "        frequences_array.append(relative_frequency * math.log2(1/relative_frequency))\n",
        "    entropies[id] = sum(frequences_array)\n",
        "  return entropies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzK_ENS14wEu"
      },
      "source": [
        "## Válidação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8h5MSPT6VsX"
      },
      "source": [
        "**Main**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZV0q2GRbF1B"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/TCC_Thalles Sobral/2-dados/germany/use-data/adjusted.csv')\n",
        "df = df.drop(columns='hashtag')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlm8l9tlvZzb"
      },
      "source": [
        "# filtrar dataframe apenas com tweets com palavras-chave\n",
        "tweets_with_key_words = select_tweets_with_key_words(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDNT1UHtvcJj"
      },
      "source": [
        "# calcular entropia dos tweets\n",
        "tweets_with_entropy = calcule_tweets_entropy(tweets_with_key_words)\n",
        "# tweets_with_entropy = calcule_tweets_entropy(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtHOSh5JQGW7"
      },
      "source": [
        "quantos é maior que 0.5? E quais as situações desses dados?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AurRaiGzvB5"
      },
      "source": [
        "keys_array = []\n",
        "values_array = []\n",
        "for keys in tweets_with_entropy:\n",
        "  keys_array.append(keys)\n",
        "  values_array.append(tweets_with_entropy[keys])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeCJkx95QOok"
      },
      "source": [
        "values_entropy = pd.Series(values_array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fTHviIfJx-h"
      },
      "source": [
        "tweets_with_key_words['entropy'] = values_entropy.values\n",
        "# df['entropy'] = values_entropy.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ecLhTm-J99u"
      },
      "source": [
        "# df.to_csv('tweets-with-entropy.csv')\n",
        "tweets_with_key_words.to_csv('tweets-with-entropy.csv')\n",
        "!cp tweets-with-entropy.csv \"drive/My Drive/TCC_Thalles Sobral/2-dados/germany/use-data\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}