{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "geographic-distance-tecnique.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJG5vpC0jV89oAB2bfgDkG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThazSobral/tcc/blob/main/geographic_distance_tecnique.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSi_ONTJWNGr"
      },
      "source": [
        "# Técnica de distância geográfica.\n",
        "\n",
        "by: João Porto de Albuquerque"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSHeS_xX39BC"
      },
      "source": [
        "## Ajuste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8x_00uy4Mlp"
      },
      "source": [
        "Primeiro fazemos todos os **ajustes** necessários para realizar o teste da técnica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0bO1_zj5BTZ",
        "outputId": "a7f8365e-baa7-4f82-a716-2ef1632ae335",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Montar do drive no notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohoobecC4Zua"
      },
      "source": [
        "Em seguida fazemos a **importação** das primeiras **bibliotecas** e do nosso **dataset**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ffr9hyuNXQMI"
      },
      "source": [
        "# Importar bibliotecas\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Importar dataset\n",
        "df = pd.read_csv('/content/drive/My Drive/TCC_Thalles Sobral/2-dados/germany/use-data/adjusted.csv', header=0)\n",
        "\n",
        "# Exibir os dados\n",
        "# df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu5TJ__eg4b8"
      },
      "source": [
        "Podemos verificar **quantos tweets há** no nosso dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-hXGacKr44Z",
        "outputId": "5d1d0e5e-50c2-438a-f897-14f947be428f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Mostrar quantos tweets há no nosso dataframe\n",
        "print(f'Há { len(df) } tweets no total.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Há 60524 tweets no total.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DRj48mlDqN2"
      },
      "source": [
        "## Identificando regiões afetadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVgzDOqUEdj9"
      },
      "source": [
        "1. As **características** dos **eventos** são definidos com base no **modelo digital de elevação** e os **dados oficiais** (ou seja, de sensores).\n",
        "2. A identificação das **áreas de captação** foi feita utilizando um conjunto de ferrametas **ArcHydro** para ArcGIS. \n",
        "  * Primeiramente foram definidos os **canais de drenagem**, o que resultou em dados vetorias.\n",
        "  * E por fim as **áreas de captação** foram identificadas utilizando as junções do rio, que foram definidas utilizando o arquivo vetorial de canal de drenagem.\n",
        "3. O calculando o nível relativo da água (ou severidade da inundação) foi baseado na medição de 185 estações. Esse cálculo foi feito seguindo a definiçao a baixo:\n",
        "~~~\n",
        "relative_level = nível médio relativo\n",
        "max_level = nível máximo de água diária\n",
        "mean_level = nível médio de água da enchente (total)\n",
        "~~~\n",
        "`relative_level = max_level - mean_level`\n",
        "\n",
        "> Em caso de **valores negativos** pode indicar que a estação **não foi afetada**, o que **valores positivos** podem indicar **o contrário**.\n",
        "\n",
        "> Em caso de mais de uma estação na mesma bácia hidrográfica, o nível relativo de água é cálculado somando o valor relativo de cada estação e depois calculada a média aritmética do conjunto. Onde esse resultado definirá se a bácia foi afetada ou não.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzCVb-M9D0Ie"
      },
      "source": [
        "## Coletando informações de mídia social (Twitter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9NBZUS7L7HG"
      },
      "source": [
        "Essa etapa se dividi nas seguintes etapas:\n",
        "* Filtragem baseada em palavras-chave;\n",
        "* Análise do conteúdo, e;\n",
        "* Condificação temática."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjXOjMFhMXZo"
      },
      "source": [
        "### Filtragem baseada em palavras-chave"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovfkAw2HMhPs"
      },
      "source": [
        "> Antes filtrar o tweets por palavras-chave filtramos por campo de georreferência, ou seja, **somente tweets georreferenciados** passam para esse etapa. Isso pode ser feito na própria API do Twitter ou através de um script."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-x_8altNNOC"
      },
      "source": [
        "O filtro por palavras-chave considera palavras (alemão e inglês) relacionadas a eventos de inundação, como descrito a seguir:\n",
        "\n",
        "**German**\n",
        "\n",
        "* *hochwasser*\n",
        "* *flut*\n",
        "* *überschwemmung*\n",
        "\n",
        "**Addiotional-words in German**\n",
        "\n",
        "* *deich*\n",
        "* *sandsack*\n",
        "\n",
        "**English**\n",
        "\n",
        "* *flood*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqohrD6Ky2bg"
      },
      "source": [
        "# definir as palavras em inglês\n",
        "key_words_english = ['flood']\n",
        "\n",
        "# definir as palavras em alemão\n",
        "key_words_german = ['hochwasser',\n",
        "                     'flut',\n",
        "                     'überschwemmung']\n",
        "\n",
        "# definir as palavras adicionais em alemão\n",
        "key_addiotional_words_german = ['deich',\n",
        "                                'sandsack']\n",
        "\n",
        "# combinar palavras-chave\n",
        "key_words = key_words_english + key_words_german + key_addiotional_words_german"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCrtlOD2_aPw"
      },
      "source": [
        "# definir função para retornar somente aos tweets que contém as palavras-chaves\n",
        "def select_tweets_with_key_words (df):\n",
        "  return df[df.tweet.str.contains('|'.join(key_words), na=False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF7nLfyo_-Qh",
        "outputId": "6716a958-741f-4443-c8a3-e96213732add",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# chamar a função para selecionar os tweets passando o dataframe completo\n",
        "tweets_with_key_words = select_tweets_with_key_words(df)\n",
        "\n",
        "# mostrar a quantidade de tweets que foram encontrados dentro do dataframe\n",
        "print(f'Foram encontrados {len(tweets_with_key_words)} tweets contendo as palavras-chave definidas.')\n",
        "\n",
        "# mostrar tweets que foram encotrados entro do dataframe\n",
        "# tweets_with_key_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Foram encontrados 405 tweets contendo as palavras-chave definidas.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWa98HDYGj2J"
      },
      "source": [
        "### Análise de conteúdo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvsXUGkmHHxN"
      },
      "source": [
        "> **Só** são analisados os **tweets que contém** as **palavras-chave**.\n",
        "\n",
        "Os tweets são **analisados e rotulados manualmente** (por três pesquisadores) dentro de **três classes**:\n",
        "* (0) - fora do tópico;\n",
        "* (1) - no tópico, mas não relevante, e;\n",
        "* (2) - no tópico e relevante.\n",
        "\n",
        "> O **tweet no tópico** (nesse trabalha) é aquele que se **refere ao evento** de inundação, mas **não contém informações relevantes**. \n",
        "\n",
        "> O **tweet relevante** (nesse trabalha) é definido como, aquele que **contém informações** que possam **contribuir para a consciência situacional**, ou seja, que pode ser útil para outras pessoas e/ou agências."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSsuvkKfH0ZO",
        "outputId": "c7f10268-0045-4ac4-e674-f202636a3704",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# adicionar uma variável para cada rótulo da análise de conteúdo\n",
        "topic_out = len(tweets_with_key_words.loc[(tweets_with_key_words['relevance'] == 0)])\n",
        "topic_in = len(tweets_with_key_words.loc[(tweets_with_key_words['relevance'] == 1)])\n",
        "topic_in_and_relevance = len(tweets_with_key_words.loc[(tweets_with_key_words['relevance'] == 2)])\n",
        "# topic_out = len(df.loc[(df['relevance'] == 0)])\n",
        "# topic_in = len(df.loc[(df['relevance'] == 1)])\n",
        "# topic_in_and_relevance = len(df.loc[(df['relevance'] == 2)])\n",
        "\n",
        "# exibir os rótulos com as respectivas quantias de tweets\n",
        "print(f'''\n",
        " - fora do tópico: {topic_out};\n",
        " - no tópico: {topic_in}, e;\n",
        " - no tópico e relevante: {topic_in_and_relevance}\n",
        "''')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " - fora do tópico: 35;\n",
            " - no tópico: 187, e;\n",
            " - no tópico e relevante: 183\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XJGqKPplfrA",
        "outputId": "af51054e-4bca-495c-c3e6-2a7d621b8e91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# exibir todos os tweets rotulados como no tópico\n",
        "print(f'No geral são {topic_in + topic_in_and_relevance} tweets marcados como no tópico.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No geral são 370 tweets marcados como no tópico.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34zaREGMMfLp"
      },
      "source": [
        "### Codificação temática"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncz2rpL-MjFu"
      },
      "source": [
        "Os tweets \"no tópico\", sendo relevantes ou não passaram por uma codificação que avalia seu conteúdo (também e forma manual). Essa avaliação consiste em **verificar o conteúdo e rotular o tweet** dentro das seguintes classe\n",
        "* (0) - other;\n",
        "* (1) - volunteer actions;\n",
        "* (2) - media reports;\n",
        "* (3) - traffic conditions;\n",
        "* (4) - first-hand observations;\n",
        "* (5) - official actions, e;\n",
        "* (6) - infrastructure damage;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn0KohYBOo61",
        "outputId": "8e2232e7-1428-4800-a549-954e8ea2fde4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# adicionar uma variável para cada rótulo da codificação temática\n",
        "outhers = len(tweets_with_key_words[(tweets_with_key_words['theme']) == 0])\n",
        "media_report = len(tweets_with_key_words[(tweets_with_key_words['theme']) == 1])\n",
        "traffic_condition = len(tweets_with_key_words[(tweets_with_key_words['theme']) == 2])\n",
        "firsthand_observation = len(tweets_with_key_words[(tweets_with_key_words['theme']) == 3])\n",
        "official_action = len(tweets_with_key_words[(tweets_with_key_words['theme']) == 4])\n",
        "damage_to_infrastruture = len(tweets_with_key_words[(tweets_with_key_words['theme']) == 5])\n",
        "volunteer_action = len(tweets_with_key_words[(tweets_with_key_words['theme']) == 6])\n",
        "\n",
        "# outhers = len(df[(df['theme']) == 0])\n",
        "# media_report = len(df[(df['theme']) == 1])\n",
        "# traffic_condition = len(df[(df['theme']) == 2])\n",
        "# firsthand_observation = len(df[(df['theme']) == 3])\n",
        "# official_action = len(df[(df['theme']) == 4])\n",
        "# damage_to_infrastruture = len(df[(df['theme']) == 5])\n",
        "# volunteer_action = len(df[(df['theme']) == 6])\n",
        "\n",
        "# exibir a quantidade de tweets que são rotulados conforme a codificação temática\n",
        "print(f'''\n",
        " - ação voluntaria: {volunteer_action}\n",
        " - relatório de mídia: {media_report}\n",
        " - condição de tráfego: {traffic_condition}\n",
        " - observação em primeira mão: {firsthand_observation}\n",
        " - ação oficial: {official_action}\n",
        " - dano a infraestrutura: {damage_to_infrastruture}\n",
        " - outros: {outhers}''')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " - ação voluntaria: 9\n",
            " - relatório de mídia: 71\n",
            " - condição de tráfego: 54\n",
            " - observação em primeira mão: 26\n",
            " - ação oficial: 69\n",
            " - dano a infraestrutura: 21\n",
            " - outros: 155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4EYouqhT-LY"
      },
      "source": [
        "### Estabelecer relações geográficas entre tweets e os eventos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skmDUWziUO08"
      },
      "source": [
        "Para estabelecer a **relação de proximidade** para cada tweet é realizado um cálculo de resulta na **distância geográfica** (em metros) entre o **tweet e a bacia hidrográfica** mais próxima.\n",
        "\n",
        "> tweets localizados **dentro da área** das bacias afetadas têm a **distância igual a 0m**.\n",
        "\n",
        "> a relação de **gravidade** (severidade) é igual ao **nível relativo da água** da bacia que o tweet está localizado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HniFrDao2BWk",
        "outputId": "aefdffee-70d0-4b14-ed3f-ac17183afca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# adicionando variável com quantidade e tweets entro das bacias\n",
        "tweets_within_the_affected_basins = len(df[df['distance [m]'] == 0])\n",
        "\n",
        "# exibir quantidade de tweets que estão dentro das bacias\n",
        "print(f'São {tweets_within_the_affected_basins} tweets localizados dentro da bacia afetada')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "São 1577 tweets localizados dentro da bacia afetada\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZEDeIGaD_Ks"
      },
      "source": [
        "## Analisando as relações geográficas entre as informações sobre os eventos e as mensagens da mídia social"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWWHmlijcTfS"
      },
      "source": [
        "Os objetivos dessa análise são dois:\n",
        "* identificar **padrões espaciais** na ocorrência de tweets \"no tópico\" que podem estar **associados** à **distância** e o **nível relativo de água**, e;\n",
        "* explorar mais as **possíveis diferenças** entre os **padrões de origem** e as **codificações dos tweets** no tópico.\n",
        "\n",
        "> De acordo com o trabalho original foi constatado que há uma **maior probabilidade** de **tweets no tópico** ao redor das **bacias com níveis de água mais altos** comparados com bacias de níveis de água mais baixos.\n",
        "\n",
        "> Para essa análise foram **utilizados** apenas tweets localizados **dentro de uma distância de 100 km** de bacias afetadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84fldOEngm3y"
      },
      "source": [
        "Nessa etapa é utilizado **GAM** (Generalized Aritmetic Model) com um **link logísitico** e **dois preditores** (**nível relativo de água** em metros e **log de base 10 da distância euclidiana** em quilometros para a **bacia mais próxima afetada**).\n",
        "\n",
        "> Para **evitar resultados excessivamente influenciados** por valores extremos, foram feitos a seguitens alterações:\n",
        "> * nível relativo da água entre + 1m e -1m;\n",
        "> * distancias < 10km recebem 10km (antes de calcular o logaritmo).\n",
        "\n",
        "O GAM implementado (do pacote R 'mgcv') **ajusta automaticamente de liberdade** efetivos do spline com um processo de validação cruzada generalizado, além de ser um 'bam' que é apropriado para **grandes conjuntos de dados**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWI4gv5Czyw4"
      },
      "source": [
        "Foram ajustados **GAMs alternativos** que representem os preditores como termos **aditivos** (duas splines univariadas) ou **interativos** (uam spline bivariada). Para o modelo **aditivo** foi aplicado um **limite de liberdade** de **3 graus**, e para o modelo **interativo** um **limite** de **5 graus**, sendo a finalidade desses objetivos **evitar oscilações excessivas** nos splines resultantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbCuc4Pv_11F"
      },
      "source": [
        "Além dos GAMs serem utilizados por causa dos recursos visuais, mas também têm a função de **calcular** as **razões de chance e riscos relativos** (proporção de probabilidades) **associados** à **distância** e **nível relativo da água**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJxhxyVAzDyG"
      },
      "source": [
        "> O odds ratios (probablidade de relação) e risco relativo são calculados para **<= 10 km** versus **30 km** de distância das áreas afetadas, e para um nível relativo da água **+0,75 m** versus **-0,75 m** mantendo o **outro preditor constante**.\n",
        "> Para esse cálculo é feito operando em cima de um preditor em diferentes níveis do outro preditor.\n",
        "~~~\n",
        " - gravity_ratio = relação de gravidade\n",
        " - nível de água relativa da captura na localização do tweet\n",
        "~~~\n",
        "`gravity_ratio[tweet] = relative_level[tweet]`\n",
        "\n",
        "> É aplicao o **bootstrap** de bloco espacial para obter **intervalos de confiança** percentil no nível de **95%**.\n",
        "> O processo de **bootstrap** foi **repetido 2500 vezes** a fim de obter os **intervalos de confiança** de percentil de **95%**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNn5_cHR12dw"
      },
      "source": [
        "Exploração dos tweets para modelar a **probabilidade** de um **tweet no tópico pertencer a um subtipo** específico.\n",
        "\n",
        "> Essa análise é realizada em tweets no tópico **dentro do buffer de 100 km** (resultando 320 no trabalho original).\n",
        "\n",
        "> O modelo foi ajustado para **identificar padrões tweets como relevantes** (resultando 169 no trabalho original) **versus** os ***não relevantes** em relação a **distância** e ao **nível relativo da água**. Isso foi realizado para responder a **questão** dos **tweets mais relevantes** são fortemente **concetrado**s nas proximidades das **áreas afetadas** ou em **bacias** com **níveis relativos de água** mais **elevados**.\n",
        "\n",
        "Cálculo da **relação geográfica** com o **tweet**\n",
        "~~~\n",
        " - tweet_interface = relação do tweet\n",
        " - tweet_localization = localização do tweet\n",
        " - hydrographic_basin = bacia hidrográfica afetada\n",
        "~~~\n",
        "`tweet_interface = tweet_localization - hyrographic_basin`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrcZdKO2_PKy"
      },
      "source": [
        "> Como a amostra é pequena, somente **GAMs sem termo de interação** foram considerados, e apenas **resumos gráficos** e **numéricos básicos** são fornecidos para **análise exploratória** desses padrões."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2Ljr6T64MdI"
      },
      "source": [
        "''' \n",
        "para mais informações:\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html\n",
        "'''\n",
        "# importe bibliotecas necessárias\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "\n",
        "# extrai valores de severidade (níveis relativos de água) de cada dia\n",
        "sev08 = df['sev08'].values\n",
        "sev09 = df['sev09'].values\n",
        "sev10 = df['sev10'].values\n",
        "\n",
        "# concatene todos os valores de severidade coletados\n",
        "sev = np.concatenate((sev08, sev09, sev10))\n",
        "\n",
        "# instancia o modelo para normalização\n",
        "model = MaxAbsScaler()\n",
        "# treine o modelo para realizar normalização com esses valores\n",
        "model.fit(sev.reshape(-1, 1))\n",
        "\n",
        "# transforme os valores de acordo com o modelo\n",
        "'''\n",
        "convertendo os arrays em 2D (porque o modelo só funciona com 2D)\n",
        "'''\n",
        "sev08 = model.transform(sev08.reshape(-1,1))\n",
        "# sev09 = model.transform(sev09.reshape(-1,1))\n",
        "# sev10 = model.transform(sev10.reshape(-1,1))\n",
        "\n",
        "# conveter os arrays para 1D novamente\n",
        "sev08 = sev08.flatten()\n",
        "sev09 = sev09.flatten()\n",
        "sev10 = sev10.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIIvlxgM_rph"
      },
      "source": [
        "# atribui todas as diantancia que for menor ou igual a 10000 (10 km) atribui 10000\n",
        "# df.loc[df['distance [m]'] <= 10000, 'distance'] = 10000\n",
        "\n",
        "# passar a distancia pelo log10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EcNz-J06o1M",
        "outputId": "f49fb9ae-4b5e-485f-f363-ed311a2f00cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "'''\n",
        "para mais informações de correlação:\n",
        "https://medium.com/brdata/correla%C3%A7%C3%A3o-direto-ao-ponto-9ec1d48735fb\n",
        "'''\n",
        "corr_dist_sev08 = df['distance [m]'].corr(df['sev08'])\n",
        "corr_dist_sev09 = df['distance [m]'].corr(df['sev09'])\n",
        "corr_dist_sev10 = df['distance [m]'].corr(df['sev10'])\n",
        "\n",
        "print(f'Graus de correlação de distancia para os dias:\\n08{corr_dist_sev08}\\n09{corr_dist_sev09}\\n10{corr_dist_sev10}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Graus de correlação de distancia para os dias:\n",
            "08-0.367923978782031\n",
            "09-0.4470906959929109\n",
            "10-0.46411051960810135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi3mw0A_Le9F"
      },
      "source": [
        "# realizar bootstraping para separar os dados que seram passados para o modelo\n",
        "import pandas\n",
        "import numpy as np\n",
        "\n",
        "# n = 5000\n",
        "# values = np.random.uniform(size=(n, 5))\n",
        "\n",
        "# columns = ['a', 'b', 'c', 'd', 'e']\n",
        "# df = pandas.DataFrame(values, columns=columns)\n",
        "\n",
        "# %timeit df.iloc[np.random.randint(n, size=n)]\n",
        "\n",
        "# randlist = pandas.DataFrame(index=np.random.randint(n, size=n))\n",
        "# %timeit df.merge(randlist, left_index=True, right_index=True, how='right')\n",
        "\n",
        "# %timeit df.merge(pandas.DataFrame(index=np.random.randint(n, size=n)), left_index=True, right_index=True, how='right')\n",
        "\n",
        "# df\n",
        "\n",
        "# metodo mais rapido para bootstraping\n",
        "# s = pd.Series(np.random.uniform(size=100))\n",
        "# s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMl1rvidWAh3"
      },
      "source": [
        "# TESTES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iGOg2rnatM6"
      },
      "source": [
        "# separar dados de treino e teste\n",
        "# importe a biblioteca necessária\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# define as variaveis de entrada\n",
        "X = df[['distance [m]', 'sev08']]\n",
        "# define as variaveis de saida \n",
        "y = df['flood']\n",
        "\n",
        "# separe os conjuntos de treino e teste\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, df.flood, test_size=.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZigTfOR-TC3C",
        "outputId": "e4c15b47-640e-4450-bbd9-a872738a5a25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df.rename(columns={'distance [m]': 'distance'}, inplace=True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>tweet</th>\n",
              "      <th>created_at</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>distance</th>\n",
              "      <th>sev08</th>\n",
              "      <th>sev09</th>\n",
              "      <th>sev10</th>\n",
              "      <th>flood</th>\n",
              "      <th>relevance</th>\n",
              "      <th>theme</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>irgendjemand hat mir gestern gesagt das er mic...</td>\n",
              "      <td>2013-06-08 13:33:07+02</td>\n",
              "      <td>429,79</td>\n",
              "      <td>5,915,818</td>\n",
              "      <td>122596</td>\n",
              "      <td>-24</td>\n",
              "      <td>-67</td>\n",
              "      <td>-127</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@ho1ger das gleiche bild übrigens im office, w...</td>\n",
              "      <td>2013-06-08 13:33:09+02</td>\n",
              "      <td>708,059</td>\n",
              "      <td>5,342,364</td>\n",
              "      <td>66842</td>\n",
              "      <td>1</td>\n",
              "      <td>-79</td>\n",
              "      <td>-114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@sensatzionell bin selbst halber berliner. wen...</td>\n",
              "      <td>2013-06-08 13:33:10+02</td>\n",
              "      <td>797,734</td>\n",
              "      <td>5,829,275</td>\n",
              "      <td>67270</td>\n",
              "      <td>-8</td>\n",
              "      <td>-10</td>\n",
              "      <td>-20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>tired bro??!!! djeeerome @ ice 672 http://t.co...</td>\n",
              "      <td>2013-06-08 13:33:14+02</td>\n",
              "      <td>522,889</td>\n",
              "      <td>5,881,956</td>\n",
              "      <td>33741</td>\n",
              "      <td>-24</td>\n",
              "      <td>-67</td>\n",
              "      <td>-127</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>und tschüss! (@ köln bonn airport (cgn) w/ 8 o...</td>\n",
              "      <td>2013-06-08 13:33:14+02</td>\n",
              "      <td>367,861</td>\n",
              "      <td>5,638,052</td>\n",
              "      <td>71798</td>\n",
              "      <td>-54</td>\n",
              "      <td>-105</td>\n",
              "      <td>-161</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60519</th>\n",
              "      <td>60519</td>\n",
              "      <td>gosh</td>\n",
              "      <td>why am i even still awake #gosh</td>\n",
              "      <td>2013-06-10 23:59:37+02</td>\n",
              "      <td>512,133</td>\n",
              "      <td>5,280,630</td>\n",
              "      <td>410343</td>\n",
              "      <td>-157</td>\n",
              "      <td>-183</td>\n",
              "      <td>-199</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60520</th>\n",
              "      <td>60520</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@doyo_da toll. xd</td>\n",
              "      <td>2013-06-10 23:59:40+02</td>\n",
              "      <td>355,787</td>\n",
              "      <td>5,709,831</td>\n",
              "      <td>305102</td>\n",
              "      <td>-49</td>\n",
              "      <td>-95</td>\n",
              "      <td>-151</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60521</th>\n",
              "      <td>60521</td>\n",
              "      <td>NaN</td>\n",
              "      <td>family portrait! :) @ osteria tarantina http:/...</td>\n",
              "      <td>2013-06-10 23:59:44+02</td>\n",
              "      <td>798,509</td>\n",
              "      <td>5,828,321</td>\n",
              "      <td>66394</td>\n",
              "      <td>-8</td>\n",
              "      <td>-10</td>\n",
              "      <td>-20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60522</th>\n",
              "      <td>60522</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@j_taekwoon guten tag !!!! 즐거운하루하시구요! 저는이제 자러 ...</td>\n",
              "      <td>2013-06-10 23:59:50+02</td>\n",
              "      <td>395,454</td>\n",
              "      <td>5,771,434</td>\n",
              "      <td>234868</td>\n",
              "      <td>-36</td>\n",
              "      <td>-59</td>\n",
              "      <td>-99</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60523</th>\n",
              "      <td>60523</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@torgator appletv v2 mit jailbreak.</td>\n",
              "      <td>2013-06-10 23:59:56+02</td>\n",
              "      <td>543,002</td>\n",
              "      <td>6,017,844</td>\n",
              "      <td>98705</td>\n",
              "      <td>13</td>\n",
              "      <td>142</td>\n",
              "      <td>209</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60524 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0 hashtags  ... relevance theme\n",
              "0               0      NaN  ...         0     0\n",
              "1               1      NaN  ...         0     0\n",
              "2               2      NaN  ...         0     0\n",
              "3               3      NaN  ...         0     0\n",
              "4               4      NaN  ...         0     0\n",
              "...           ...      ...  ...       ...   ...\n",
              "60519       60519     gosh  ...         0     0\n",
              "60520       60520      NaN  ...         0     0\n",
              "60521       60521      NaN  ...         0     0\n",
              "60522       60522      NaN  ...         0     0\n",
              "60523       60523      NaN  ...         0     0\n",
              "\n",
              "[60524 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2rLtv786xa8",
        "outputId": "411674cb-da53-4b99-fcec-ce0f0f3070ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "# Aplicar GAM\n",
        "# importe as bibliotecas necessárias\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.gam.api import GLMGam, BSplines\n",
        "# from statsmodels.gam.tests.test_penalized import df_autos\n",
        "\n",
        "# definir os splines para o modelo dentro do dataset\n",
        "# x_spline = df_autos[['weight', 'hp']]\n",
        "x_spline = df[['distance', 'sev08']]\n",
        "\n",
        "'''\n",
        "instancie a classe, passando:\n",
        "- os dados\n",
        "- graus de liberdade\n",
        "- grau do spline\n",
        "'''\n",
        "# bs= BSplines(x_spline, df=[12, 10], degree=[3,3])\n",
        "bs= BSplines(x_spline, df=[3, 5], degree=[2, 2])\n",
        "\n",
        "# definir penalização, onde o comprimento da lista deve ser igual ao numero de termos regulares no smoother\n",
        "alpha = np.array([21833888.8, 6460.38479])\n",
        "# alpha = np.array([cnsultar no trabalho])\n",
        "\n",
        "'''\n",
        "crie  o modelo a partir de uma fórmula e dataframe, passando:\n",
        "- formula que especifica o modelo\n",
        "- dados do modelo\n",
        "- a instancia da classe\n",
        "- a penalidade do modelo, onde o comprimento deve ser igual ao smoother\n",
        "'''\n",
        "# gam_bs = GLMGam.from_formula('city_mpg ~ fuel + drive', data=df_autos, smoother=bs, alpha=alpha)\n",
        "gam_bs = GLMGam.from_formula('flood ~ distance + sev08', data=df, smoother=bs, alpha=alpha)\n",
        "\n",
        "# estimar parãmetros e criar uma instancia da classe GLMGamResults\n",
        "res_bs = gam_bs.fit()\n",
        "\n",
        "# plotar as estimativas do modelo\n",
        "# res_bs.plot_partial(0, cpr=True)\n",
        "# res_bs.plot_partial(1, cpr=True)\n",
        "\n",
        "# alpha = np.array([8283989284.5829611, 14628207.58927821])\n",
        "\n",
        "# gam_bs = GLMGam.from_formula('city_mpg ~fuel + drive', data = df_autos, smoother=bs, alpha=alpha, family=sm.families.Poisson())\n",
        "\n",
        "# res_bs = gam_bs.fit()\n",
        "\n",
        "# res_bs.plot_partial(0, cpr=True)\n",
        "\n",
        "# res_bs.plot_partial(1, cpr=True)\n",
        "\n",
        "# gam_bs.select_penweight()[0]\n",
        "\n",
        "# gam_bs.select_penweight_kfold()[0]\n",
        "\n",
        "res_bs.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Generalized Linear Model Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>         <td>flood</td>      <th>  No. Observations:  </th>  <td> 60524</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                <td>GLMGam</td>      <th>  Df Residuals:      </th> <td>60517.00</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model Family:</th>        <td>Gaussian</td>     <th>  Df Model:          </th> <td>    6.00</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Link Function:</th>       <td>identity</td>     <th>  Scale:             </th> <td>0.0062392</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>                <td>PIRLS</td>      <th>  Log-Likelihood:    </th> <td>  67761.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>            <td>Tue, 03 Nov 2020</td> <th>  Deviance:          </th> <td>  377.58</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                <td>14:52:26</td>     <th>  Pearson chi2:      </th>  <td>  378.</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Iterations:</th>          <td>3</td>        <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "       <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th>   <td>    0.0421</td> <td>    0.001</td> <td>   43.694</td> <td> 0.000</td> <td>    0.040</td> <td>    0.044</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>distance</th>    <td> 2.213e-10</td> <td> 3.44e-09</td> <td>    0.064</td> <td> 0.949</td> <td>-6.53e-09</td> <td> 6.97e-09</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>sev08</th>       <td> 9.472e-05</td> <td>  6.3e-06</td> <td>   15.034</td> <td> 0.000</td> <td> 8.24e-05</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>distance_s0</th> <td>   -0.0099</td> <td>    0.003</td> <td>   -3.102</td> <td> 0.002</td> <td>   -0.016</td> <td>   -0.004</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>distance_s1</th> <td>    0.0049</td> <td>    0.002</td> <td>    3.102</td> <td> 0.002</td> <td>    0.002</td> <td>    0.008</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>sev08_s0</th>    <td>   -0.0023</td> <td>    0.004</td> <td>   -0.575</td> <td> 0.566</td> <td>   -0.010</td> <td>    0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>sev08_s1</th>    <td>   -0.0381</td> <td>    0.001</td> <td>  -26.449</td> <td> 0.000</td> <td>   -0.041</td> <td>   -0.035</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>sev08_s2</th>    <td>   -0.0116</td> <td>    0.003</td> <td>   -4.233</td> <td> 0.000</td> <td>   -0.017</td> <td>   -0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>sev08_s3</th>    <td>    0.0550</td> <td>    0.003</td> <td>   20.749</td> <td> 0.000</td> <td>    0.050</td> <td>    0.060</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                 Generalized Linear Model Regression Results                  \n",
              "==============================================================================\n",
              "Dep. Variable:                  flood   No. Observations:                60524\n",
              "Model:                         GLMGam   Df Residuals:                 60517.00\n",
              "Model Family:                Gaussian   Df Model:                         6.00\n",
              "Link Function:               identity   Scale:                       0.0062392\n",
              "Method:                         PIRLS   Log-Likelihood:                 67761.\n",
              "Date:                Tue, 03 Nov 2020   Deviance:                       377.58\n",
              "Time:                        14:52:26   Pearson chi2:                     378.\n",
              "No. Iterations:                     3                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "===============================================================================\n",
              "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
              "-------------------------------------------------------------------------------\n",
              "Intercept       0.0421      0.001     43.694      0.000       0.040       0.044\n",
              "distance     2.213e-10   3.44e-09      0.064      0.949   -6.53e-09    6.97e-09\n",
              "sev08        9.472e-05    6.3e-06     15.034      0.000    8.24e-05       0.000\n",
              "distance_s0    -0.0099      0.003     -3.102      0.002      -0.016      -0.004\n",
              "distance_s1     0.0049      0.002      3.102      0.002       0.002       0.008\n",
              "sev08_s0       -0.0023      0.004     -0.575      0.566      -0.010       0.006\n",
              "sev08_s1       -0.0381      0.001    -26.449      0.000      -0.041      -0.035\n",
              "sev08_s2       -0.0116      0.003     -4.233      0.000      -0.017      -0.006\n",
              "sev08_s3        0.0550      0.003     20.749      0.000       0.050       0.060\n",
              "===============================================================================\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_NqkQcu_x_u"
      },
      "source": [
        "# Teste PyGAM\n",
        "!pip install pygam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H7q-GKH_3xf"
      },
      "source": [
        "from pygam import GAM, s, f\n",
        "from pygam import PoissonGAM\n",
        "\n",
        "first_gam = GAM(s(0, n_splines=5) + s(1) + f(2) + s(3), distribution='gamma', link='log')\n",
        "second_gam = PoissonGAM(s(0, n_splines=5) + s(1) + f(2) + s(3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm3ADuZ76zr7"
      },
      "source": [
        "# verificar os resultados"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}